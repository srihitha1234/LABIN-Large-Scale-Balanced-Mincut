# -*- coding: utf-8 -*-
"""algorithms.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15V0hdWtGppxL7FX1fHVXrod8zeiIWqja
"""

#ALGORITHM

import numpy as np
from scipy.sparse.linalg import svds
from scipy.linalg import eig
from sklearn.cluster import KMeans

def kmeans_clustering(X, k):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X.T)
    return kmeans.cluster_centers_.T

def compute_sparse_representation_matrix(X, k, m):
    W = kmeans_clustering(X, k)

    # Compute distances between data points and anchors
    distances = np.linalg.norm(X[:, np.newaxis, :] - W.T[np.newaxis, :, :].T,
                               axis=2)

    # Find the indices of the k-nearest neighbors for each data point
    indices = np.argsort(distances, axis=1)[:, :k]

    # Ensure that the indices are within the valid range
    indices = np.clip(indices, 0, m-1)

    # Construct the sparse representation matrix B
    B = np.zeros((X.shape[1], m))
    for i in range(X.shape[1]):
        for j in indices[i]:
            B[i, j] = np.linalg.norm(X[:, i] - W[:, j])**2 / 2.0

    return B

def update_Y(X, R, k):
    Y = np.random.rand(X.shape[1], k)
    return Y

def LABIN(X, k, m, c, max_iter=100, tol=1e-5):
    # Step 2: Find m anchors W with k-means
    B = compute_sparse_representation_matrix(X, k, m)
    D = np.diag(np.sum(B, axis=1))
    P = np.linalg.inv(D) @ B

    Y_star = np.random.rand(X.shape[1], c)

    for _ in range(max_iter):
        # Step 4: Reduced SVD on Q
        Q = np.concatenate((P, np.ones((P.shape[0], 1))), axis=1)
        U, _, _ = svds(Q, c)

        # Step 8: Update according to Eq. (32) and perform eigendecomposition
        L, V = eig(U.T @ P @ P.T @ U)
        idx = np.argsort(L)[::-1][:c]
        Lambda = np.diag(L[idx])
        V = V[:, idx]

        # Step 9: Update Yâˆ—
        Y_star = U @ np.sqrt(Lambda) @ V.T
        Y_star = Y_star[:, :k]
        # Ensure Y_star has the same number of columns as Y

        for _ in range(max_iter):
            # Step 11: Update R
            R = np.dot(Y_star, Y_star.T)

            # Step 12: Update Y
            Y = update_Y(X, R, k)

            # Check convergence of problem (38)
            delta_Y = Y
            if np.linalg.norm(delta_Y, 'fro') < tol:
                break

            Y_star = Y

        # Check convergence of problem (26)
        if np.linalg.norm(delta_Y, 'fro') < tol:
            break

    return Y

# Example usage:
np.random.seed(42)
d, n = 10, 10
X = np.random.rand(d, n)

k = 5
m = 5
c = 3

Y_result = LABIN(X, k, m, c)
print("Clustering Result (Y):")
print(Y_result)